---
title: "Custom input and output files"
output: html_notebook
---

# Do first

1. Navigate to the `5-files/` folder.
2. Open `5-files.Rproj` as an RStudio project in a new R session. (Click on `5-files.Rproj` in RStudio's file manager.)
3. Run the setup chunk below.

```{r, include = FALSE}
setwd(file.path(rprojroot::find_rstudio_root_file(), "5-files"))
source("../config/options.R")
```

# About

This part of the workshop aims to demonstrate how to reproducibly track input and output files with `drake`.

# Motivation: possible storage slowness

When `drake` runs your model, it [serializes](https://en.wikipedia.org/wiki/Serialization) the output twice: once in `keras::serialize_model()` and again in [`drake`'s storage system](https://github.com/richfitz/storr). This may slow down workflows with quick models and enormous datasets.

Let's find out if our own workflow suffers such slowness. First, we run the workflow.

```{r}
source("R/packages.R")
source("R/functions.R")
source("R/plan.R")
make(plan)
```

Then, we look at build times.

```{r}
build_times()
```

`drake` records the time it took to fully process the model.

```{r}
build <- build_times(model, type = "build")$elapsed
build
```

And the time it took just to run the command

```{r}
command <- build_times(model, type = "command")$elapsed
command
```

The relative difference is the overhead incurred by `drake`.

```{r}
sprintf("%.2f%%", 100 * (build - command) / build)
```

In the customer churn case study, the overhead is not so bad. However, you should perform this runtime check in your own deep learning projects. If the overhead is too high, you should avoid `drake`'s one-size-fits-all storage system and save your models to custom files. 

# How to track files reproducibly.

For `drake` plans, there are three functions to reproducibly track files.

Function | Purpose | Works with directories? | Works inside custom functions?
---|---|---|---
`file_in()` | Track **input** files. | Yes | Yes
`file_out()` | Track **output** files | Yes | No
`knitr_in()` | Track `knitr` report files | No | No

For now, let's focus on `file_in()` and` file_out()`. We already have an example of `file_in()` to load our data.

```{r}
plan %>%
  filter(target == "data") %>%
  pull(command) %>%
  `[[`(1)
```

`file_in()` tells `make()` to fingerprint and track `customer_churn.csv`. As we saw in the `3-iterate` exercises, `drake` updates the downstream targets when the data file changes.

```{r}
config <- drake_config(plan)
vis_drake_graph(config,  from = file_store("../data/customer_churn.csv"))
```

`file_out()` works similarly, but for output files. Output files from one target can serve as input files for other targets.

```{r}
example_plan <- drake_plan(
  data_file_target = {
    data1 <- read_csv(file_in("input.csv"))
    data2 <- munge(data)
    write_csv(data1, file_out("data1.csv"))
    write_csv(data2, file_out("data2.csv"))
  },
  analysis_target = analyze_files(file_in(c("data1.csv", "data2.csv")))
)

config <- drake_config(example_plan)
vis_drake_graph(config)
```


# Exercise: back to customer churn

Let's save our model to a custom file. We will use [`save_model_hdf5()`](https://keras.rstudio.com/reference/save_model_hdf5.html) and `load_model_hdf5()` from [`keras`](https://keras.rstudio.com).

Follow the directions in the comments of `R/plan.R` and `R/functions.R`. If you get stuck and need to reset your files, start over with a fresh copy of the notebooks and supporting files ([`learndrake::save_notebooks()`](https://github.com/wlandau/learndrake)). You can peek at [this chapter of the manual](https://ropenscilabs.github.io/drake-manual/churn.html#increasing-efficiency) for hints.

When you are done, check your dependency graph.

```{r}
source("R/packages.R")
source("R/functions.R")
source("R/plan.R")
config <- drake_config(plan)
vis_drake_graph(config)
```

Our graph should look something like this.

```{r}
readRDS("img/graph.rds")
```

Now let's fit our model and run the downstream analyses.

```{r}
make(plan)
```

Sanity check: are all our targets up to date now?

```{r}
outdated(config)
```

```{r}
make(plan)
```

Our file-based approach frees us up to see the progression of the model run.

```{r}
loadd(progression)
plot(progression)
```


Our model is in a file.

```{r}
load_model_hdf5("model.h5")
```

What happens if we remove it?

```{r}
unlink("model.h5")
```

Which targets are outdated now?

```{r}
outdated(config)
```

Which targets get rebuilt when we call `make(plan)`?

```{r}
make(plan)
```
