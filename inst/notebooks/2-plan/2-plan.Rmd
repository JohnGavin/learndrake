---
title: "Build up a drake plan"
output: html_notebook
---

# Do first

1. Navigate to the `2-plan/` folder.
2. Open `2-plan.Rproj` as an RStudio project in a new R session. (Click on `2-plan.Rproj` in RStudio's file manager.)
3. Check that your working directory is correct. It should be `2-plan/`.

```{r}
basename(getwd()) # Should be "2-plan"
```

4. Run the setup code chunk below. (Click on the green arrow on the right.)

```{r, include = FALSE}
source("../config/options.R")
```

# About

To implement the customer churn prediction workflow, you will create a `drake` plan. A `drake` plan is a data frame with code. It has the *targets* you will build and the R *commands* to build those targets. Helpful references:

- The chapter on `drake` plans: <https://books.ropensci.org/drake/plans.html>
- The opening presentation of this workshop: <https://wlandau.github.io/learndrake>

# Dependencies

The commands in your `drake` plan will depend on the packages and functions introduced in `1-functions.Rmd`. Run code chunk below to load them now. (Click on the green arrow on the right.)

```{r message = FALSE}
source("R/packages.R")  # Load the packages.
source("R/functions.R") # Define our custom functions.
```

Take a quick moment to look at `packages.R` and `functions.R`. Open them in RStudio and see how they are organized.

# Start the plan

Your initial plan will

1. Read the customer churn data from a CSV file, and
2. Clean it up for the deep learning models.

Code for (1):

```{r, eval = FALSE}
# file_in() will tell drake to rebuild targets when the file changes.
churn_data <- split_data(file_in("../data/customer_churn.csv"))
```

Code for (2):

```{r, eval = FALSE}
churn_recipe <- prepare_recipe(churn_data)
```

Now, let's create a new `drake` plan with these two steps as *targets*:

```{r}
plan <- drake_plan(
  churn_data = split_data(file_in("../data/customer_churn.csv")),
  churn_recipe = prepare_recipe(churn_data)
)
```

The plan is a data frame with the targets and commands.

```{r, paged.print = FALSE}
plan
```

# Run the plan

When you first created the plan, you did not actually run the commands. To actually run the workflow, use `make()`.

```{r}
make(plan)
```

# Inspect the targets

Targets `churn_data` and `churn_recipe` now live in a special `.drake/` folder.

```{r}
list.files(all = TRUE)
```

The `.drake/` folder is a special kind of cache (<https://github.com/richfitz/storr>) and the files and subfolders were designed for machines only. No humans allowed!

```{r}
list.files(".drake/data")
```

To get the targets from the cache, use `drake` functions `loadd()` and `readd()`. Let's check the data for potential problems.

```{r, paged.print = FALSE}
readd(churn_data)
```

```{r}
loadd(churn_recipe)
class(churn_recipe)
```

# Interlude: dependencies

`drake` understands the dependency relationships among

1. The two targets in the plan.
2. The CSV data you declared with `file_in()`.
3. The functions you loaded with `source("R/functions.R")`.

To see for yourself, visualize the graph.

```{r}
vis_drake_graph(plan)
```

Target `churn_data` depends on file `customer_churn.csv`, and target `churn_recipe` depends on function `prepare_recipe()` and target `churn_data`. 

```{r}
deps_target(churn_data, plan)
```

```{r}
deps_target(churn_recipe, plan)
```

How does `drake` know all this? Static code analysis: <http://adv-r.had.co.nz/Expressions.html#ast-funs>. In other words, `drake` dissects the structure of your code without actually running it. That means the order of the targets in the plan does not matter. In fact, if we reverse the recipe and the data, it has no effect.

```{r}
plan <- drake_plan(
  churn_recipe = prepare_recipe(churn_data), # previously last
  churn_data = split_data(file_in("../data/customer_churn.csv"))
)
```

We still get the same graph.

```{r}
vis_drake_graph(plan)
```

And our targets are still up to date.

```{r}
outdated(plan)
```

```{r}
make(plan)
```

If you *invalidate* the targets and run `make()` from scratch, still `churn_recipe` runs second. `make()` always uses *dependency relationships* to run the correct targets in the correct order.

```{r}
clean()
make(plan)
```

# Build up the plan

Let's add two model runs to the plan. One model has a relu activation function:

```{r, eval = FALSE}
# Do not run now.
run_relu <- test_model(act1 = "relu", churn_data, churn_recipe)
```

The other has a sigmoid activation function:

```{r, eval = FALSE}
# Do not run now.
run_sigmoid <- test_model(act1 = "sigmoid", churn_data, churn_recipe)
```

Your turn: add these targets to the plan.

```{r}
plan <- drake_plan(
  churn_data = split_data(file_in("../data/customer_churn.csv")),
  churn_recipe = prepare_recipe(churn_data),
  run_relu = , # Write the command between the equals sign and comma.
  run_sigmoid = # Write the command here.
)
```

Visualize the graph to check the plan. `run_relu` and `run_sigmoid` should be new targets that depend on `churn_data`, `churn_recipe`, `test_model()`, and the custom functions called from `test_model()`.

```{r}
vis_drake_graph(plan)
```

`churn_data` and `churn_recipe` are up to date from last time, and `run_relu` and `run_sigmoid` are new.

```{r}
outdated(plan)
```

So `make()` skips the data and just runs the models. Run `make()` below and ignore any TensorFlow messages that pop up.

```{r}
make(plan) # slow
```

Those models took a long time to run, right? That is why `make()` tries to keep them up to date.

```{r}
outdated(plan)
```

```{r}
make(plan) # fast
```

Now, check your model runs. Each should be a data frame with the accuracy and features of a model.

```{r, paged.print = FALSE}
readd(run_relu)
```

```{r, paged.print = FALSE}
readd(run_sigmoid)
```

# Add another model

Now, let's add a third model with a different activation function. Use the `act1 = "softmax"` this time.

```{r}
plan <- drake_plan(
  churn_data = split_data(file_in("../data/customer_churn.csv")),
  churn_recipe = prepare_recipe(churn_data),
  run_relu = test_model(act1 = "relu", churn_data, churn_recipe),
  run_sigmoid = test_model(act1 = "sigmoid", churn_data, churn_recipe),
  run_softmax = # Write a new call to test_model() with act1 = "softmax"
)
```

The previous two runs should be up to date. Only `run_softmax` should be outdated.

```{r}
outdated(plan)
```

```{r}
vis_drake_graph(plan)
```

Run the softmax model.

```{r}
make(plan)
```

Did it come out right?

```{r, paged.print = FALSE}
readd(run_softmax)
```

# Pick the best model.

Let's aggregate all the model runs into a single data frame. Define a new `best_run` target with following command:

```{r, eval = FALSE}
# Do not run here.
bind_rows(run_relu, run_sigmoid, run_softmax) %>%
  filter(accuracy == max(accuracy))
```

Write the command in the plan below. Note: commands do not always need to be function calls. They can be arbitrary code chunks too.

```{r}
plan <- drake_plan(
  churn_data = split_data(file_in("../data/customer_churn.csv")),
  churn_recipe = prepare_recipe(churn_data),
  run_relu = test_model(act1 = "relu", churn_data, churn_recipe),
  run_sigmoid = test_model(act1 = "sigmoid", churn_data, churn_recipe),
  run_softmax = test_model(act1 = "softmax", churn_data, churn_recipe),
  best_run = # Write the command to get the best model run.
)
```

The next `make()` should just build `runs` and be quick.

```{r}
make(plan)
```

It should contain one row with the accuracy and features of the best model.

```{r}
readd(best_run)
```

Now, let's run the best model and tell `drake` to hold on to the trained model. Below, we use the `target()` function for extra customization because Keras models need the special `"keras"` storage format (<https://books.ropensci.org/drake/plans.html#special-data-formats-for-targets>). Below, write the command `train_best_model(best_run, churn_recipe)`.

```{r}
plan <- drake_plan(
  churn_data = split_data(file_in("../data/customer_churn.csv")),
  churn_recipe = prepare_recipe(churn_data),
  run_relu = test_model(act1 = "relu", churn_data, churn_recipe),
  run_sigmoid = test_model(act1 = "sigmoid", churn_data, churn_recipe),
  run_softmax = test_model(act1 = "softmax", churn_data, churn_recipe),
  best_run = bind_rows(run_relu, run_sigmoid, run_softmax) %>%
    filter(accuracy == max(accuracy)),
  best_model = target( # We use target() to customize the target.
    , # Write the command, train_best_model(best_run, churn_recipe).
    format = "keras" # Tell drake to store the target as a Keras model.
  )
)
```

Run the model.

```{r}
make(plan)
```

Now, `drake` has the trained model in the cache.

```{r}
readd(model)
```

# Recap

Rome was not built in a day, and neither is your `drake` plan. Building up a plan is an gradual iterative process.

1. Write some targets targets in the plan.
2. Check the plan with `outdated(plan)` and `vis_drake_graph(plan)`.
3. Run `make()` to build the new targets.
4. Check the output with `loadd()` and `readd()`.
5. Repeat.

# Changes

What if a function changes?

```{r}
define_model <- function(churn_recipe, units1, units2, act1, act2, act3) {
  input_shape <- ncol(
    juice(churn_recipe, all_predictors(), composition = "matrix")
  )
  keras_model_sequential() %>%
    layer_dense(
      units = units1,
      kernel_initializer = "uniform",
      activation = act1,
      input_shape = input_shape
    ) %>%
    layer_dropout(rate = 0.2) %>% # previously 0.1
    layer_dense(
      units = units2,
      kernel_initializer = "uniform",
      activation = act2
    ) %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(
      units = 1,
      kernel_initializer = "uniform",
      activation = act3
    )
}
```

`drake` automatically detects the change and rebuilds the affected targets.

```{r}
outdated(plan)
```

```{r}
vis_drake_graph(plan)
```

```{r}
make(plan)
```

Same story if you change a `file_in()` dataset.

# Time savings and reproducibility

All your targets should be up to date now.

```{r}
outdated(plan)
```

```{r}
make(plan)
```

This is tangible evidence of reproducibility. It is tangible evidence that your output is in sync with the code and data you have right now. So if someone else were to run your code, they should get the same results as you. You can be confident without having to rerun everything from scratch. This is how `drake` saves time while increasing your ability to trust your research.
