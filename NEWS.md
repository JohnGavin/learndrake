# learndrake 0.0.2.9000

* Improve the motivating example: try a bunch of models without saving them, *then* automatically pick the best one based on accuracy. The workflow is still oversimplified, but it is closer to how people use deep learning in real life.
* Build up the plan gradually. Rome was not built in a day, and neither is anyone's `drake` plan. The second chapter of the workshop walks students through the (usually unspoken) iterative process of adding targets, checking them, running them, and adding more.
* New chapter on [dynamic branching](https://books.ropensci.org/drake/dynamic.html).
* Combine the chapters on external files and literate programming together.
* Clarify the intent of the `learnr` tutorials (and change their names). `learndrakechanges` focuses on how `drake` response to changes in the workflow, and `learndrakestatic` is all about static branching.
* `learndrakestatic` (previously `learndrakeplans`) used to be the most difficult part of the workshop. Now, the exercises are easier, more educational, and full of `learnr` hints.
